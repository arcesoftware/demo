{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arcesoftware/demo/blob/main/BertTokenizer.Polars.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yi3Bs32cg0Vj",
        "outputId": "8ce1caef-b25d-4a0a-a295-cb35a0e79270"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.8/dist-packages (0.15.8)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from polars) (4.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install polars\n",
        "import torch\n",
        "import polars as pd\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import matplotlib.pyplot as plt\n",
        "import logging\n",
        "import timeit\n",
        "import string\n",
        "import re\n",
        "import itertools\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Use the timeit module to measure the execution time of specific sections of code\n",
        "def measure_time(func):\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start = timeit.default_timer()\n",
        "        result = func(*args, **kwargs)\n",
        "        end = timeit.default_timer()\n",
        "        print(f'Executed in {end - start:.6f} seconds')\n",
        "        return result\n",
        "    return wrapper \n",
        "\n",
        "# Load the pre-trained model tokenizer (vocabulary)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "# Use a generator function to yield the data one batch at a time\n",
        "def process_text(file):\n",
        "    with open(file, encoding='utf-8-sig') as f:\n",
        "        # Process each line of the file\n",
        "        for line in f:\n",
        "            # Use a regular expression to remove punctuation and lowercase the text\n",
        "            line = re.sub(f'[{string.punctuation}]', '', line)\n",
        "            line = line.lower()\n",
        "            # Tokenize the text and yield the result\n",
        "            yield tokenizer.tokenize(line)\n",
        "\n",
        "# Use the map function to apply the process_text function to each line of the file\n",
        "text_tokens = map(process_text, ['bible.txt'])\n",
        "\n",
        "# Use the itertools module to flatten the list of lists\n",
        "text_tokens = list(itertools.chain.from_iterable(text_tokens))\n",
        "\n",
        "# Create a Polars DataFrame from the list of tokens\n",
        "df = pd.DataFrame({'tokens': text_tokens})\n",
        "\n",
        "# Use the head() method to print the first 10 rows of the DataFrame\n",
        "print(df.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "budzt34MhGSt",
        "outputId": "eec4e301-c660-42f8-e749-5fa2e6633a1d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (10, 1)\n",
            "┌─────────────────────────────┐\n",
            "│ tokens                      │\n",
            "│ ---                         │\n",
            "│ list[str]                   │\n",
            "╞═════════════════════════════╡\n",
            "│ [\"11\", \"in\", ... \"earth\"]   │\n",
            "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
            "│ []                          │\n",
            "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
            "│ [\"12\", \"and\", ... \"upon\"]   │\n",
            "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
            "│ [\"the\", \"face\", ... \"the\"]  │\n",
            "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
            "│ ...                         │\n",
            "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
            "│ [\"13\", \"and\", ... \"light\"]  │\n",
            "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
            "│ []                          │\n",
            "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
            "│ [\"14\", \"and\", ... \"light\"]  │\n",
            "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
            "│ [\"from\", \"the\", \"darkness\"] │\n",
            "└─────────────────────────────┘\n"
          ]
        }
      ]
    }
  ]
}